{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef576a7",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Training Data & Feature views</span>\n",
    "\n",
    "<span style=\"font-width:bold; font-size: 1.4rem;\">This is the second part of the quick start series of tutorials about Hopsworks Feature Store. This notebook explains how to read from a feature group and create training dataset within the feature store</span>\n",
    "\n",
    "## üóíÔ∏è In this notebook we will see how to create a training dataset from the feature groups: \n",
    "\n",
    "1. Retrieving Feature Groups\n",
    "2. Feature Group investigation\n",
    "3. Transformation functions\n",
    "4. Feature Views\n",
    "5. Training Datasets\n",
    "6. Training Datasets with Event Time filter\n",
    "\n",
    "\n",
    "\n",
    "![tutorial-flow](images/02_training-dataset.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc700df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üîÆ ü™ù Connecting to Feature Store and Retrieving Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b274779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1d40f",
   "metadata": {},
   "source": [
    "> In order to retrieve necessary Feature Group we can use `FeatureStore.get_or_create_feature_group()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0295ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_weather = fs.get_or_create_feature_group(\n",
    "    name = 'weather_fg',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_calendar = fs.get_or_create_feature_group(\n",
    "    name = 'calendar_fg',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_electricity = fs.get_or_create_feature_group(\n",
    "    name = 'electricity_fg',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518fa772",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:#ff5f27;\">üïµüèª‚Äç‚ôÇÔ∏è Feature Groups Investigation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b35bf",
   "metadata": {},
   "source": [
    "We can use `FeatureGroup.show()` method to select top n rows. \n",
    "\n",
    "Also we use method `FeatureGroup.read()` in order **to aggregate queries**, which are the output of next methods:\n",
    "\n",
    "- `FeatureGroup.get_feature()` to get specific feature from our Feature Group.\n",
    "\n",
    "- `FeatureGroup.select()` to get a subset of features from our Feature Group.\n",
    "\n",
    "- `FeatureGroup.select_all()` to get all features from our Feature Group.\n",
    "\n",
    "- `FeatureGroup.select_except()` to get all features except a few from our Feature Group.\n",
    "\n",
    "- `FeatureGroup.filter()` to apply specific filter to the feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad244c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_weather.select_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f90326",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_weather.select_all().read().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_calendar.select_except(['index']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_electricity.select('demand').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_electricity.filter(fg_electricity.demand > 10000).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6316b0ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:#ff5f27;\">üßëüèª‚Äçüî¨ Transformation functions</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f97bc",
   "metadata": {},
   "source": [
    "Hopsworks Feature Store provides functionality to attach transformation functions to training datasets.\n",
    "\n",
    "Hopsworks Feature Store also comes with built-in transformation functions such as `min_max_scaler`, `standard_scaler`, `robust_scaler` and `label_encoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8743407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t_func.name for t_func in fs.get_transformation_functions()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a7f5e9",
   "metadata": {},
   "source": [
    "We can retrieve transformation function we need .\n",
    "\n",
    "To attach transformation function to training dataset provide transformation functions as dict, where key is feature name and value is online transformation function name.\n",
    "\n",
    "Also training dataset must be created from the Query object. Once attached transformation function will be applied on whenever save, insert and get_serving_vector methods are called on training dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7997ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transformation functions.\n",
    "standard_scaler = fs.get_transformation_function(name = 'standard_scaler')\n",
    "label_encoder = fs.get_transformation_function(name = 'label_encoder')\n",
    "\n",
    "#Map features to transformations.\n",
    "mapping_transformers = {\n",
    "    \"rrp_positive\": standard_scaler,\n",
    "    \"rrp_negative\": standard_scaler,\n",
    "    \"school_day\": label_encoder,\n",
    "    \"holiday\": label_encoder\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490cc6b2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\">üíº Query Preparation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_weather.select_all().join(\n",
    "                            fg_calendar.select_all()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101bd6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_query = fg_weather.select_all()\\\n",
    "                        .join(\n",
    "                            fg_calendar.select_all(),\n",
    "                            on = ['index']\n",
    "                        )\\\n",
    "                        .join(\n",
    "                            fg_electricity.select_all(),\n",
    "                            on = ['index']\n",
    "                        )\n",
    "fg_query.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe60fb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> ‚öôÔ∏è Feature View Creation </span>\n",
    "\n",
    "`Feature Views` stands between **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create **Feature Views** which store a metadata of our data. Having **Feature Views** we can create **Training Dataset**.\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "\n",
    "In order to create Feature View we can use `FeatureStore.create_feature_view()` method.\n",
    "\n",
    "We can specify next parameters:\n",
    "\n",
    "- `name` - name of a feature group.\n",
    "\n",
    "- `version` - version of a feature group.\n",
    "\n",
    "- `labels`- our target variable.\n",
    "\n",
    "- `transformation_functions` - functions to transform our features.\n",
    "\n",
    "- `query` - query object with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9017f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.create_feature_view(\n",
    "    name = 'electricity_feature_view',\n",
    "    version = 1,\n",
    "    labels = ['demand'],\n",
    "    query = fg_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e30e1c",
   "metadata": {},
   "source": [
    "For now `Feature View` is saved in Hopsworks and we can retrieve it using `FeatureStore.get_feature_view()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\n",
    "    name = 'electricity_feature_view',\n",
    "    version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fec859",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8db51c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "To create training dataset we use `FeatureView.create_training_data()` method.\n",
    "\n",
    "Here are some importand things:\n",
    "\n",
    "- It will inherit the name of FeatureView.\n",
    "\n",
    "- The feature store currently supports the following data formats for\n",
    "training datasets: **tfrecord, csv, tsv, parquet, avro, orc**.\n",
    "\n",
    "- We can choose necessary format using **data_format** parameter.\n",
    "\n",
    "- **start_time** and **end_time** in order to filter dataset in specific time range.\n",
    "\n",
    "- We can create **train, test** splits using `create_train_test_split()`. \n",
    "\n",
    "- We can create **train,validation, test** splits using `create_train_validation_test_splits()` methods.\n",
    "\n",
    "- The only thing is that we should specify desired ratio of splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3815e74e",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Dataset with train and test splits</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e850a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view.create_train_test_split(\n",
    "    test_size = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42438d4f",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Simple Training Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05571c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view.create_training_data(\n",
    "    description = 'training_dataset',\n",
    "    data_format = 'csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f587477",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Dataset with train, validation and test splits</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee7f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view.create_train_validation_test_split(\n",
    "    validation_size = 0.2,\n",
    "    test_size = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90bcdc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> ü™ù Retrieving Datasets </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca998b3",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Simple Training Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ac103",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = feature_view.get_training_data(\n",
    "    training_dataset_version = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a16c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea1f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb040725",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df78dc9",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Dataset with train and test splits</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3390b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = feature_view.get_train_test_split(\n",
    "    training_dataset_version = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeadcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee598e1b",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Dataset with train, validation and test splits</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = feature_view.get_train_validation_test_split(\n",
    "    training_dataset_version = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae58221",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0e7b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd048ef",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Creating Training Datasets with Event Time filter</span>\n",
    "\n",
    "First of all lets import **datetime** from datetime library and set up a time format.\n",
    "\n",
    "Then we can define start_time point and end_time point.\n",
    "\n",
    "Finally we can create training dataset with data in specific time bourders. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4969183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def from_unix_to_datetime(unix):\n",
    "    return datetime.utcfromtimestamp(unix).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be0070",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "start_time_train = int(float(datetime.strptime('2017-01-01 00:00:01',date_format).timestamp()) * 1000)\n",
    "end_time_train = int(float(datetime.strptime('2018-02-01 23:59:59',date_format).timestamp()) * 1000)\n",
    "\n",
    "start_time_test = int(float(datetime.strptime('2018-02-02 23:59:59',date_format).timestamp()) * 1000)\n",
    "end_time_test = int(float(datetime.strptime('2019-02-01 23:59:59',date_format).timestamp()) * 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc1b825",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#ff5f27;\"> ‚õ≥Ô∏è Simple Training Dataset with event time</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddca72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view.create_training_data(\n",
    "    description = 'data_2017_2018',\n",
    "    data_format = 'csv',\n",
    "    start_time = start_time_train,\n",
    "    end_time = end_time_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lim, y_train_lim = feature_view.get_training_data(\n",
    "    training_dataset_version = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ccc9c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ffb438",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> Next Steps</span>\n",
    "\n",
    "In the next notebook, we will train a model on the Training Dataset we created in this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
